\section{Introduction}

Consider classic supervised binary classification.  A learner is fit to a training set consisting of labeled examples from the positive and negative classes.  In contrast, \textit{Positive-unlabeled} (PU) \textit{learning} is a form of \textit{partially-supervised} binary classification where labeled data exists for only one class, i.e.,~positive.  The training set consists of a (positive) labeled set,~$\Pos$, and an unlabeled set,~$\Unlabel$, which is composed of both positive and negatives examples all of whose labels are unknown.  By convention, ${\Pos\cap\Unlabel=\emptyset}$.  PU~learning is applicable to both the \textit{transductive} setting, where the goal is to label~$\Unlabel$ as accurately as possible, as well as the \textit{inductive} setting, where the objective is to maximize the generalization performance on an unseen test set.

There are many applications where labeled data for one class may be unavailable or prohibitively expensive/difficult to collect. Domains where PU~learning has been applied include: land-cover classification~\cite{Li:2011}, protein similarity prediction~\cite{Elkan:2008}, disease gene identification~\cite{Yang:2012}, deceptive/incentivized review identification~\cite{Ren:2014}, targeted marketing~\cite{Yi:2017}, and prescription drug interaction analysis~\cite{Liu:2017}. The PU~learning framework can also be used for outlier detection given a set of inlier examples.~\cite{Scott:2009}

State-of-the-art PU learning algorithms generally rely on a cost-sensitive learning framework where each unlabeled example is simultaneously treated as both positive \textit{and} negative valued with each instance's class weights proportional to its specific label confidence.~\cite{Elkan:2008}  These previous works generally made one or more assumptions about the composition of~$\Pos$ and~$\Unlabel$. Most PU~learning paradigms use more traditional machine learning algorithms such as support vector machines~\cite{Elkan:2008} and logistic regression~\cite{Lee:2003}.  We are not aware of any previous PU~research that specifically focused on leveraging the significant, recent advances in deep learning.

The primary contribution of this directed research project (DRP) will be \toolname\ --- our new PU~learning algorithm built around a deep, bifurcated autoencoder.  The remainder of this document is structured as follows.  Section~\ref{sec:Siamese} introduces the Siamese neural network, from which our algorithm was inspired.  Section~\ref{sec:Toolname} provides an overview of our novel architecture.  Section~\ref{sec:Deliverables} outlines this project's planned deliverables while Section~\ref{sec:Timeline} concludes with a summary of the project timeline.

