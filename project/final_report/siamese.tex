\section{Siamese Network}\label{sec:Siamese}

\textit{Few-shot learning} encompasses classification tasks where there is a large number of classes but very limited labeled data per class --- as few as a single example in the case of ``one-shot learning.''  Few-shot learning is particularly common in computer vision spaces such as facial recognition~\cite{Guo:2017} and fingerprint identification~\cite{Marasco:2016}.

First proposed by Koch\etal~\cite{Koch:2015}, the \textit{Siamese neural network} is specifically targeted towards these few-shot, vision-based learning tasks.  Formally, the network is a function, $\SiamFunc:\xDomain\mapsto\mathbb{R}^m$, where ${m\in\mathbb{Z}_{{+}}}$ is a hyperparameter. Consider two examples, $\xBase,\xBase'\in\xDomain$, with labels $y$ and $y'$, and distance metric ${\delta:\mathbb{R}^m\times\mathbb{R}^{m}\mapsto\mathbb{R}_{{\geq}0}}$ satisfying the identity, symmetry, and triangle-inequality properties.  The \textbf{fundamental intuition} of Siamese networks is that if ${y=y'}$, then $\siamDist{\SiamFunc}{\xBase}{\xBase'}$ should be \textit{small}.  Otherwise if ${y\ne y}'$, $\siamDist{\SiamFunc}{\xBase}{\xBase'}$ should be \textit{large}.  The relative definitions of ``small'' and ``large'' vary by application and as a function of~$m$.

Siamese networks are trained to satisfy this fundamental intuition through a unique \textit{triplet loss function} --- whose name derives from the three training examples required for each loss calculation.  Define $\exA$ as the \underline{a}nchor example used as the reference for comparison.  \underline{P}ositive example,~$\exP$, has the same label as~$\exA$ while \underline{n}egative example,~$\exN$, has a different label than both $\exA$~and~$\exP$.

Eq.~\eqref{eq:Loss:Triplet} defines the triplet loss formally.  Hyperparameter ${\alpha\in\mathbb{R}_{{>}0}}$ enforces the relative distinctions of ``small'' and ``large'' mentioned earlier.   The loss is minimized by either reducing the distance between the mapped representation of examples in the same class --- i.e.,~$\siamDist{\SiamFunc}{\exA}{\exP}$ --- or by increasing the distance between the mapped representation of instances with different labels, i.e.,~$\siamDist{\SiamFunc}{\exA}{\exN}$.

\begin{equation}\label{eq:Loss:Triplet}
  \lTrip = \max\Big\{ \siamDist{\SiamFunc}{\exA}{\exP} - \siamDist{\SiamFunc}{\exA}{\exN} + \alpha, 0 \Big\}
\end{equation}
